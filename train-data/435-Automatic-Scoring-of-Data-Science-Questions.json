{"url":"https://support.hackerrank.com/hc/en-us/articles/1500001422301-Automatic-Scoring-of-Data-Science-Questions","body":"<h2>Overview</h2>\n<p><span style=\"font-weight: 400;\">HackerRank Projects for Data Science allows you to set up automatic scoring for your custom project-based real-world questions to assess Data Scientists.</span></p>\n<p><span style=\"font-weight: 400;\">This is an optional step under the <strong>Setup Project</strong> step of the <a href=\"https://support.hackerrank.com/hc/en-us/articles/360034149714-Creating-a-Data-Science-Question\" target=\"_blank\" rel=\"noopener\">Data Science question creation workflow</a> that allows you to set up automatic scoring. You can add evaluation scripts, submission files, solution notebooks, and so on in the section <strong>Add evaluation files</strong></span><span style=\"font-weight: 400;\">. All files uploaded in this field will be hidden and unavailable to the candidate. These files will be downloaded in the Juypter session during scoring and evaluation inside the \"evaluation_files\" folder. The configuration file <em>Hackerrank.yml</em> needs to have the scoring command. The scoring command would be executed automatically after a candidate submits the solution. </span></p>\n<p>In this article, we will walk you through the process of setting up automatic scoring while creating your own Data Science Question on HackerRank Projects. </p>\n<h2>\n<span style=\"font-weight: 400;\">Setting Up Automatic Scoring of Data Science Questions </span><span style=\"font-weight: 400;\"></span>\n</h2>\n<p><span style=\"font-weight: 400;\">There are two options to set up scoring</span></p>\n<h4><strong>Standard Metrics<img src=\"https://support.hackerrank.com/hc/article_attachments/12733140567571\" alt=\"image1.png\"></strong></h4>\n<p><span style=\"font-weight: 400;\">Select a metric that you would like to use to evaluate your candidate’s submission. </span></p>\n<p><span style=\"font-weight: 400;\">Add the file name which you would ask your candidate to submit their final submission.<img src=\"https://support.hackerrank.com/hc/article_attachments/12733197298835\" alt=\"image6.png\"></span></p>\n<p><span style=\"font-weight: 400;\">Upload the actual output file containing the result, which will be used to generate the score and Map the required fields for scoring.<img src=\"https://support.hackerrank.com/hc/article_attachments/12733140558739\" alt=\"image2.png\"></span><span style=\"font-weight: 400;\"></span></p>\n<p><span style=\"font-weight: 400;\">Upload the expected submission file that you expect the candidate to submit and Map the required fields for scoring. This file will be used to validate the scoring setup.</span><span style=\"font-weight: 400;\"></span></p>\n<p><span style=\"font-weight: 400;\">Click on the validate and save buttons to validate the changes. In case of errors, follow error logs and messages to debug. </span><span style=\"font-weight: 400;\"><br></span></p>\n<h4><strong>Custom scoring<img src=\"https://support.hackerrank.com/hc/article_attachments/12733141060499\" alt=\"image7.png\"></strong></h4>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Create a program to evaluate candidate submissions.  </span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">(</span><em><span style=\"font-weight: 400;\">Example: a python program that will compare the candidate's submission.csv with the uploaded actual_output.csv and calculate the desired model performance metric such as accuracy, recall, precision, f-score, etc., convert that into a % and return FS_SCORE: X% as output)</span></em></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\">\n<span style=\"font-weight: 400;\">Ensure the scoring program returns in the format “</span><em><span style=\"font-weight: 400;\">FS_SCORE: X%.</span></em><span style=\"font-weight: 400;\">”</span>\n</li>\n</ul>\n<p class=\"wysiwyg-text-align-center\"><img src=\"https://support.hackerrank.com/hc/article_attachments/360102602913/Score_python_file.png\" alt=\"Score_python_file.png\" width=\"538\" height=\"831\"></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\">\n<span style=\"font-weight: 400;\">Upload all the necessary files </span><em><span style=\"font-weight: 400;\">(</span></em><em><span style=\"font-weight: 400;\">actual_output.csv)</span></em> <span style=\"font-weight: 400;\">needed to run the evaluation program successfully, along with the scoring program(</span><em><span style=\"font-weight: 400;\">score.py, score.sh),</span></em><span style=\"font-weight: 400;\"> in the evaluation section.<img src=\"https://support.hackerrank.com/hc/article_attachments/12733295374995\" alt=\"Screenshot_2023-01-04_at_8.21.18_PM__1_.png\"></span><span style=\"font-weight: 400;\"></span>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\">\n<span style=\"font-weight: 400;\">Edit the <em>hackerrank.yml</em> configuration file and add the scoring key with the scoring command. The example</span><span style=\"font-weight: 400;\"> configuration is below:</span>\n<pre class=\"c-mrkdwn__pre\" data-stringify-type=\"pre\">Scoring <br><span class=\"c-mrkdwn__br\" data-stringify-type=\"paragraph-break\"></span>command: python evaluation_files/score.py evaluation_files/actual_output.csv</pre>\n<p class=\"wysiwyg-text-align-center\"><img src=\"https://support.hackerrank.com/hc/article_attachments/360100431374/Scoring_command.png\" alt=\"Scoring_command.png\"></p>\n<span style=\"font-weight: 400;\"></span>\n</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Ensure that your evaluation script can handle edge cases and will return a score in all possible scenarios.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">An erroneous response will result in a no score, and you will be required to review the submission manually.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Click on the validate and save buttons to validate the changes. In case of errors, follow error logs and messages to debug. </span></li>\n</ul>\n<p class=\"box info\"><span style=\"font-weight: 400;\"><strong>Note: </strong>To update the evaluation files, you must re-upload them and delete the previous version.</span></p>\n<p class=\"box info\"><span style=\"font-weight: 400;\">HackerRank also offers manual scoring for the Data Science questions. Learn more about it <a href=\"https://support.hackerrank.com/hc/en-us/articles/360034149774-Manual-Scoring-of-Data-Science-Questions-\" target=\"_blank\" rel=\"noopener\">here.</a></span></p>\n<p> </p>","title":"Automatic Scoring of Data Science Questions"}